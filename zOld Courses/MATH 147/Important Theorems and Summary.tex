\documentclass[10pt,letter]{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{setspace}
\onehalfspacing
\usepackage{fullpage}
\newtheorem*{remark}{Remark}
\begin{document}
\title{Important Theorems and Definitions for MATH 147}

\chapter*{Important Definitions}
\section*{1.14: Triangle Inequality}
$|x|-|y|\leq|x+y|\leq|x| + |y|$\\ 
$|x - y| \leq |x - z| + |z - y|$

\section*{3.2: Convergence}
A sequence $(x_n)_{n=1}^\infty\in\mathbb{R}^\mathbb{N}$ is said to converge to a limit $\beta\in\mathbb{R}$ if for all $\epsilon>0$ there exists $N\in\mathbb{N}$ such that $n\geq N$ implies $|x_n-\beta|<\epsilon$. 

\section*{5.2: Definition of Cauchy Sequence}
Let $(x_n)_{n=1}^\infty\in\mathbb{R}^\mathbb{N}$. We say that $(x_n)_{n=1}^\infty$ is a Cauchy sequence if for all $\epsilon > 0$ there exists $N\in\mathbb{N}$ such that $m > n \geq N$ implies $|x_n - x_m| < \epsilon$. 

\section*{5.9: Sequentially Compact}
A subset $E \subseteq \mathbb{R}$ is said to be sequentially compact if, given a sequence $x_n \in E^\mathbb{N}$, there exists a subsequence $x_{n_k}$ of $x_n$ which converges to some element $\beta \in \mathbb{R}$, and furthermore we must have $\beta \in E$\\ 
Every sequence in E has a subsequence that converges to an element in E. 

\section*{6.2: Definition of Limit Superior and Limit Inferior}
Suppose that $(x_n)_{n=1}^\infty \in \mathbb{R}$ is a bounded sequence. We define the limit superior of $(x_n)_{n=1}^\infty$ to be $lim sup_{n\geq 1} := lim_{n\rightarrow\infty} sup_{k\geq n} x_k$, and the limit inferior to be lim inf$_{n\geq 1} := $lim$_{n\rightarrow\infty}$ inf$_{k\geq n} x_k$.

\section*{7.2: Punctured Neighbourhood}
Let $x_o\in\mathbb{R}$. We say that a set $H \subseteq\mathbb{R}$ is a punctured neighbourhood of $x_o$ if there exists $0 < \gamma \in \mathbb{R}$ such that \\ 
(i) $0 < |x - x_o| < \gamma$ implies that $x \in H$, but\\
(ii)$x_o \not\in H$. \\ 

\section*{7.3: Epsilon Delta Proofs}
Let $x_o\in\mathbb{R}$ and suppose that $E\subseteq\mathbb{R}$ contains a punctured neighbourhood of $x_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f approaches a limit $\beta\in\mathbb{R}$ as x approaches $x_o$ if for all $\epsilon>0$ there exists $\delta>0$ such that $0 < |x-x_o| < \delta$ implies $|f(x)-\beta| < \epsilon$. 

\section*{8.2: Limits Approaching From Either Side}
Let $y_o \in\mathbb{R}$ and suppose that $E \subseteq\mathbb{R}$ contains an interval $(y_o,y_o +\gamma)$ for some $\gamma>0$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f converges to a limit $\beta$ as x approaches $y_o$ from the right if: \\ 
For all $\epsilon>0$ there exists $\delta>0$ such that $y_o<x<y_o+\delta$ implies that $|f(x)-\beta| < \epsilon$. We write $lim_{x\rightarrow y_o^+}f(x) = \beta$. A similar definition holds for convergence of f to $\beta$ as x approaches $y_o$ from the left. 

\section*{9.2: Definition of Continuity}
Let $y_o\in\mathbb{R}$, and suppose that $E\subseteq\mathbb{R}$ contains a neighbourhood of $y_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f is continuous at $y_o$ if $lim_{x\rightarrow y_o}f(x) = f(y_o)$; that is, for all $\epsilon>0$ there exists $\delta>0$ such that $|x-y_o|<\delta$ implies $|f(x)-f(y_o)|<\epsilon$. We say that $f$ is continuous on E if $f$ is continuous at $y_o$ for every $y_o\in E$. 

\section*{9.3: Continuity from Either Side}
Let $y_o\in\mathbb{R}$ and suppose that $[y_o,y_o+8)\subseteq E_1$ for some $\delta_1>0$. Let $f: E_1\rightarrow\mathbb{R}$ be a function. We say that $f$ is continuous from the right at $y_o$ if $f(y_o) = lim_{x\rightarrow y_o^+}f(x)$. Continuity from the left is defined similarly. Given a closed interval $[a,b]\subseteq\mathbb{R}$, and a function $f:[a,b]\rightarrow\mathbb{R}$, we say that f is continuous on $[a,b]$ if \\ 
(i) f is continuous from the right at a\\ 
(ii) f is continuous on (a,b) \\ 
(iii) f is continuous from the left at b\\.

\section*{9.12: Bounded in E}
Let $\phi\neq E\subseteq\mathbb{R}$ and suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ is bounded on E if there exists $\mu>0$ such that $|f(x)|\leq\mu$ for all $x\in E$. In other words, $f$ is bounded on E if $sup\{|f(x)|:x\in E\}<\infty$. 

\section*{10.2: Definition of Uniform Continuity}
Let $E\subseteq\mathbb{R}$, and suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ is uniformly continuous on E if for all $\epsilon>0$ there exists $\delta>0$ such that $x,y\in E$ and $|x-y|<\delta$ implies $|f(x)-f(y)|<\epsilon$. The key new ingredient here is that $\delta>0$ is chosen before we pick the point at which we consider continuity. In other words, the same $\delta>0$ works for all $y\in E$. 

\section*{11.2: Definition of Differentiability}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Let $f:E\rightarrow\mathbb{R}$ be a function. We say that $f$ is differentiable at $x_o$ if $f'(x_o)=lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)}{h}=lim_{x\rightarrow x_o}\frac{f(x)-f(x_o)}{x-x_o}$ exists as a real number. We refer to $f'(x_o)$ as the derivative of $f$ at $x_o$. We say that $f$ is differentiable on E provided that: \\ 
(a) E is a neighbourhood of each of its points, ie E is open, and \\ 
(b) $f$ is differentiable at every point of E. 

\section*{11.11: Local Max and Local Min}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ has a local maximum at $x_o$ if there exists $\delta>0$ such that $f(x_o)\geq f(x)$ for all $x\in(x_o-\delta, x_o+\delta)$. We say that $f$ has a local minimum at $x_o$ if there exists $\delta>0$ such that $f(x_o)\leq f(x)$ for all $x\in(x_o-\delta,x_o+\delta)$.

\section*{12.7: Increasing and Decreasing on an interval}
Let $\phi\neq E\subseteq\mathbb{R}$ and $f:E\rightarrow\mathbb{R}$ be a function. We say that: \\ 
$f$  is increasing on E if $x<y$ in E implies $f(x)\leq f(y)$\\
$f$  is strictly increasing on E if $x<y$ in E implies $f(x)< f(y)$\\
$f$  is decreasing on E if $x<y$ in E implies $f(x)\geq f(y)$\\
$f$  is strictly decreasing on E if $x<y$ in E implies $f(x)> f(y)$\\ 

\section*{12.8: Derivatives on an Increasing/Decreasing Interval}
Suppose that $f,g:[a,b]\rightarrow\mathbb{R}$ are continuous and differentiable. \\ 
(I) If $f'(x)>0$ for all $x\in(a,b)$, then $f$ is strictly increasing on $(a,b)$. \\ 
(II) If $f'(x)<0$ for all $x\in(a,b)$, then $f$ is strictly decreasing on $(a,b)$. \\ 
(III) If $f'(x)=0$ for all $x\in(a,b)$, then $f$ is constant on $(a,b)$. \\ 
Proof: (I) By the Mean Value Theorem, if $a<x_1<x_2<b$, then $f$ is differentiable and continuous on $(x_1,x_2)$. So there exists $x_o\in(x_1,x_2)$ such that $f(x_2)-f(x_1)=f'(x_o)(x_2-x_1)$. But $f'(x_o)>0$, $x_2-x_1>0$, so $f(x_2)-f(x_1)>0$, ie. $f$ is strictly increasing. \\ 
(II) Apply (I) to $g=-f$ \\ 
(III) By the Mean Value Theorem, for any $a<x_1<x_2<b$, $f$ is differentiable and continuous on $(x_1,x_2)$. So there exists $x_o\in(x_1,x_2)$ such that $f(x_2)-f(x_1)=f'(x_o)(x_2-x_1)$. But $f'(x)=0$ for all $x\in(a,b)$, so $f'(x_o)=0$, whence $f(x_2)-f(x_1)$. Since $x_1<x_2$ in $(a,b)$ were arbitrary, $f$ is constant on $(a,b)$. 

\section*{12.14: Concavity}
Let $a<b\in\mathbb{R}$ and suppose that $f:(a,b)\rightarrow\mathbb{R}$ is a function. We say that $f$ is \\ 
(a) Concave up on (a,b) if $a<x_o<y_o<b$ implies that $\frac{f(x_o)+f(y_o)}{2}\geq f(\frac{x_o+y_o}{2})$. \\ 
(b) Concave down on (a,b) if $a<x_o<y_o<b$ implies that $\frac{f(x_o)+f(y_o)}{2}\leq f(\frac{x_o+y_o}{2})$. \\ 
We say that $f$ is strictly CU or CD if the inequalities are strict. 

\section*{12.17: Point of inflection}
A point $x_o\in(a,b)$ is said to be a point of inflection for $f$ if there exists $\delta>0$ such that either \\ 
(a) $f$ is strictly CU on $(x_o-\delta,x_o)$ and strictly CD on $(x_o,x_o+\delta)$, or \\ 
(b) $f$ is strictly CD on $(x_o-\delta,x_o)$ and strictly CU on $(x_o,x_o+\delta)$ 




\chapter*{Important Theorems}

\section*{3.14: Subsequences of a Convergent Sequence}
Let $(x_n)_{n=1}^\infty \in \mathbb{R}^\mathbb{N}$, and suppose $lim_{n\rightarrow\infty}x_n = \beta$. If $(x_{n_k})_{k=1}^\infty$ is any subsequence of $(x_n)_{n=1}^\infty$, then $lim_{n\rightarrow\infty}x_{n_k} = \beta$.\\ 
Proof: Let $\epsilon > 0$ and choose $N \in \mathbb{N}$ so that $n \geq N$ implies $|x_n-\beta|<\epsilon$. If $k\geq N$, then $n_k\geq k\geq N$, and so $|x_{n_k}-\beta| < \epsilon$. 

\section*{3.16: Squeeze Theorem}
Proof: Let $\epsilon > 0$. Choose $N_1 \in\mathbb{N}$ so that $n\geq N$ implies $|x_n-\beta| < \epsilon$. Choose Choose $N_2 \in\mathbb{N}$ so that $n\geq N$ implies $|z_n-\beta| < \epsilon$. Let $N=max(N_o,N_1,N_2)$. Then $n\geq N$ implies that $\beta - \epsilon < x_n \leq y_n \leq z_n < \beta + \epsilon$, so that $\beta - \epsilon < y_n < \beta + \epsilon$, ie. $|y_n - \beta| < \epsilon$. 

\section*{3.21 The comparison theorem}
Suppose $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ $\in \mathbb{R}^\mathbb{N}$ $\ni$ $lim x_n = \alpha$ and $lim y_n = \beta$. Suppose also that $\exists N_o \in \mathbb{N} \ni n \geq N_o$ implies $x_n \leq y_n$. Then $\alpha \leq \beta$. \\ 

\section*{4.3: Monotone Convergence Theorem}
(a) if $x_n$ is increasing and bounded above, then $x_n$ converges to $sup{x_n}$.\\ 
(b) if $x_n$ is decreasing and bounded below, then $x_n$ converges to $inf{x_n}$.\\ 
Proof for (a): Suppose $(x_n)_{n=1}^\infty$ is bounded above, $\beta:= sup\{x_n\}_{n=1}^\infty$ exists. Let $\epsilon > 0$. Since $\beta - \epsilon < \beta = sup\{x_n\}$, there exists $N \in \mathbb{N}$ such that $\beta - \epsilon < x_N$. Since $(x_n)_{n=1}^\infty$ is increasing, $n \geq N$ implies that $\beta - \epsilon < x_N \leq x_n \leq sup{x_n}$. That is, $x \geq N$ implies that $|x_n - \beta| < \epsilon$. 

\section*{4.8: Bolzano-Weierstrass Theorem}
Suppose that $(x_n)_{n=1}^\infty$ is a bounded sequence. Then there exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ which converges.
(Every bounded sequence has a convergent subsequence)

\section*{5.5: Cauchy Sequences}
Let $x_n$. The following are equivalent: \\ 
(a) $x_n$ is convergent, that is, there exists $\beta$ such that $lim x_n = \beta$.\\ 
(b) $x_n$ is a cauchy sequence. \\ 
Proof: $(a) \rightarrow (b)$. Suppose that $\beta \in \mathbb{R}$ and $lim_{n\rightarrow\infty} = \beta$. Let $\epsilon > 0$ and choose $N \in \mathbb{N}$ such that $n \geq N$ implies that $|x_n - \beta| < \frac{\epsilon}{2}$. If $m > n \geq N$, then \\ 
$|x_m - x_n| = |x_m - \beta + \beta - x_n|$
$\leq |x_m - \beta| + |x_n - \beta| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$. \\ 
By definition, $(x_n)_{n=1}^\infty$ is a Cauchy sequence. 

\section*{6.6: Limit Superior and Limit Inferior of Subsequences}
Let $(x_n)_{n=1}^\infty\in\mathbb{R}^\mathbb{N}$, and let $\beta = lim_{n\geq 1}sup x_n$, $\alpha = lim_{n\geq 1}inf x_n$, so that $\alpha, \beta \in \mathbb{R}\cup \{-\infty, \infty\}$. \\ 
(a) There exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ such that $lim_{k\rightarrow\infty}x_{n_k} = \beta$. \\ 
(b) There exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ such that $lim_{k\rightarrow\infty}x_{n_k} = \alpha$. \\ 
(c) If $(x_{p_k})_{k=1}^\infty$ is any convergent subsequence of $(x_n)_{n=1}^\infty$ then $\alpha\leq lim_{k\rightarrow\infty}x_{p_k}\leq\beta$

\section*{6.7: Limit Superior and Limit Inferior and Limits}
Let $(x_n)_{n=1}^\infty \in \mathbb{R}^\mathbb{N}$, and suppose that $lim_{n\rightarrow\infty} = \gamma \in \mathbb{R}$ exists. Then $lim_{n\geq 1}inf x_n = \gamma = lim_{n\geq 1}sup x_n$.\\ 
Proof: By Theorem 6.6, there exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ which converges to $\beta:= lim_{n\geq 1}supx_n$ But since $(x_n)_{n=1}^\infty$ converges to $\gamma$, every subsequence of $(x_n)_{n=1}^\infty$ also converges to $\gamma$, so $\beta = \gamma$. Similarly, $\beta = \alpha = \gamma$. 

\section*{7.11: The Squeeze Theorem}
Suppose that E contains a punctured neighbourhood of $y_o\in\mathbb{R}$ and suppose that $f, g, h: E\rightarrow\mathbb{R}$ are functions. \\ 
(a) If $f(x)\leq g(x)\leq h(x)$ for all $x\in E\backslash\{y_o\}$, and if $lim_{x\rightarrow y_o}f(x) = \alpha = lim_{x\rightarrow y_o}h(x)$, then $lim_{x\rightarrow y_o}g(x) = \alpha$. \\ 
(b) If $|g(x)|\leq \mu$ for all $x \in E\backslash\{y_o\}$, and if $lim_{x\rightarrow y_o}f(x) = 0$, then $lim_{x\rightarrow y_o}(fg)(x) =lim_{x\rightarrow y_o}f(x)g(x) = 0$.

\section*{7.12: Comparison Theorem} 
Suppose that $E \subseteq \mathbb{R}$ contains a punctured neighbourhood of $y_o\in\mathbb{R}$ and that $f, g: E\rightarrow\mathbb{R}$ are functions. Suppose furthermore that \\ 
(i) $f(x)\leq g(x)$ for all $x\in E\backslash\{y_o\}$
(ii) $lim_{x\rightarrow y_o}f(x) = \alpha$ and $lim_{x\rightarrow y_o}g(x) = \beta$ both exist. \\ 
Proof: Let $(x_n)_{n=1}^\infty \in (E\backslash\{y_o\})^\mathbb{N}$ be any sequence satisfying $lim_{n\rightarrow\infty}x_n = y_o$. Set $w_n = f(x_n)$, $z_n = g(x_n)$, $n \in \mathbb{N}$ so that $w_n\leq z_n$ for all $n\geq 1$. Note that $lim_{n\rightarrow\infty}w_n = \alpha$, and $lim_{n\rightarrow\infty}z_n = \beta$. By the Comparison Theorem for sequences, $\alpha\leq\beta$. 

\section*{8.3: Limits at a point}
Let $y_o \in\mathbb{R}$ and suppose that $E \subseteq\mathbb{R}$ contains a punctured neighbourhood of $y_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. The following statements are equivalent: \\ 
(a) $lim_{x\rightarrow y_o}f(x) = \beta \in \mathbb{R}$\\ 
(b) $lim_{x\rightarrow y_o^+}f(x) = \beta = lim_{x\rightarrow y_o^-}f(x)$\\ 
Proof: (a) implies (b) Suppose $lim_{x\rightarrow y_o}f(x) = \beta$. Let $\epsilon > 0$ and choose $\delta > 0$ such that $0 < |x-y_o| < \delta$ implies that $|f(x)-\beta|<\epsilon$. Then $y_o<x<y_o+\delta$ implies $|f(x)-\beta|<\epsilon$. By definition, $lim_{x\rightarrow y_o^+}f(x)=\beta$. Also, $y_o-\delta<x<y_o$ implies $|f(x)-\beta|<\epsilon$. By definition, $lim_{x\rightarrow y_o^-}f(x) = \beta$. \\ 
(b) implies (a) Suppose that (b) holds, and let $\epsilon > 0$. Then there exists $\delta_1>0$ such that $y_o<x<y+\delta_1$ implies that $|f(x)-\beta|<\epsilon$. Also, there exists $\delta_2 > 0$ such that $y_o-\delta_2 < x< y_o$ impies that $|f(x)-\beta|<\epsilon$. Hence, with $\delta = min(\delta_1, \delta_2)>0$, we have that $0 < |x-y_o|<\delta$ implies that either $y_o-\delta<x<y_o$, and so $|f(x)-\beta|<\epsilon$, or $y_o<x<y_o+\delta$, and so $|f(x)-\beta|<\epsilon$. 

\section*{9.4}
Let $y_o\in\mathbb{R}$ and suppose that $E\subseteq\mathbb{R}$ contains a neighbourhood of $y_o$. The following are equivalent: \\ 
(a) $f$ is continuous at $y_o$. \\ 
(b) if $(x_n)_{n=1}^\infty\in E^\mathbb{N}$ and $lim_{n\rightarrow\infty}x_n=y_o$, then $lim_{n\rightarrow\infty}f(x_n)=f(y_o)$ \\ 
Proof: (a) implies (b). Suppose $f(y_o) = lim_{x\rightarrow y_o}f(x)$. Let $\epsilon>0$. Then there exists $\delta>0$ such that $|x-y_o|<\delta$ implies $|f(x)-f(y)|<\epsilon$. Now let $(x_n)_{n=1}^\infty\in E^\mathbb{N}$ be an arbitrary sequence which satisfies $lim_{n\rightarrow\infty}x_n=y_o$. Then there exists $N\in\mathbb{N}$ such that $n\geq N$ implies $|x_n-y_o|<\delta$. But then $n\geq N$ implies $|f(x_n)-f(y_o)|<\epsilon$, showing that $lim_{n\rightarrow\infty}f(x_n) = f(y_o)$. \\ 
(b) implies (a). Suppose (b) is done, and let $\beta=f(y_o)$. Since (b) is true, if we take any sequence $(x_n)_{n=1}^\infty$ in $(E\backslash\{y_o\})^\mathbb{N}$ such that $lim_{n\rightarrow\infty}x_n = y_o$, then $lim_{n\rightarrow\infty}f(x_n)  = \beta$. By Thereom 7.8, we find that $lim_{x\rightarrow y_o}=\beta = f(y_o)$. 

\section*{9.13: Extreme Value Theorem}
Let $a<b\in\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a continuous function. Then there exists $x_o\in[a,b]$ such that $f(x)\leq f(x_o)$ for all $x\in[a,b]$. That is, $M:=sup\{f(x):x\in[a,b]\}=max\{f(x):x\in[a,b]\}$, or the supremeum of $f(x)$ is attained at some point $x_o$. \\ 
(Some point has a max in a continuous function)

\section*{9.17: Intermediate Value Theorem}
Let $a<b$ in $\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a continuous functions. Let $\beta\in\mathbb{R}$. \\ 
(a) If $f(a)<\beta<f(b)$, then there exists $x_o\in(a,b)$ such that $f(x_o)=\beta$. \\ 
(b) If $f(a)>\beta>f(b)$, then there exists $x_o\in(a,b)$ such that $f(x_o)=\beta$. \\ 
(if your continuous function goes from $f(a)$ to $f(b)$, then at some point it touches every single point in that range)

\section*{11.4: Differentiability implications}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Let $f:E\rightarrow\mathbb{R}$ be a function. The following are equivalent: \\ 
(a) $f$ is differentiable at $x_o$; ie $f'(x_o):=lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)}{h}$ exists \\ 
(b) There exists a function $F:E\rightarrow\mathbb{R}$ such that: \\
\hspace*{5mm} (i) $f(x)=F(x)(x-x_o)+f(x_o)$ and \\
\hspace*{5mm} (ii) F is continuous at $x_o$ with $F(x)=f'(x_o)$ \\ 
(c) There exists a function $T:\mathbb{R}\rightarrow\mathbb{R}$ such that $Tx=m_ox$ for some fixed constant $m_o\in\mathbb{R}$, and all $x\in\mathbb{R}$, such that $lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)-Th}{h} = 0$\\ 

----------------PROOF FROM ASSIGNMENT 9------------

\section*{12.2: Rolle's Theorem}
Let $a<b\in\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a function such that: \\ 
(a) $f$ is continuous on $[a,b]$ \\ 
(b) $f$ is differentiable on $(a,b)$\\ 
(c) $f(a) =f(b)=0$\\ 
There exists a point $x_o\in(a,b)$ where $f'(x_o)=0$ \\ 
(if your function goes from 0 to 0, then at some point the derivative is 0) 

\section*{12.4: Mean Value Theorem}
Let $a<b\in\mathbb{R}$ and $f:[a,b]\rightarrow\mathbb{R}$ be a function. Suppose that \\ 
(a) $f:[a,b]\rightarrow\mathbb{R}$ is continuous, and \\ 
(b) $f$ is differentiable on (a,b). \\ 
Then there exists $x_o\in(a,b)$ such that $f'(x_o)=\frac{f(b)-f(a)}{b-a}$\\ 
(for every continuous, differentiable function, then at some point at every interval, the derivative is equal to the line from the beginning to the end)

\section*{12.5: Cauchy's Mean Value Theorem}
Suppose that $f,g:[a,b]\rightarrow\mathbb{R}$ are continuous and differentiable. Then there exists $x_o\in(a,b)$ such that $g'(x_o)(f(b)-f(a))=f'(x_o)(g(b)-g(a))$. 

\section*{12.13: Darboux's Theorem}
Suppose that $\phi\neq E\subseteq\mathbb{R}$ and that $[a,b]\subseteq E$ for some $a<b$ in $\mathbb{R}$. Suppose furthermore that $f:E\rightarrow\mathbb{R}$ is a function and that $f'(x)$ exists for all $x\in[a,b]$. If $f'(a)<y_o<f'(b)$, then there exists $x_o\in(a,b)$ such that $f'(x_o)=y_o$. 

\section*{14.1: L'Hopital's Rule 1}
Suppose that $a<b$ in $\mathbb{R}$ and $x_o\in(a,b)$. Suppose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, except possibly at $x_o$, and that $lim_{x\rightarrow x_o^+}f(x)=0=lim_{x\rightarrow x_o^+}g(x)$. If $lim_{x\rightarrow x_o^+}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow x_o^+}\frac{f(x)}{g(x)} = \alpha$

\section*{14.2: L'Hopital's Rule 2}
Suppoose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, and that $lim_{x\rightarrow\infty}f(x)=0=lim_{x\rightarrow\infty}g(x)$. If $lim_{x\rightarrow\infty}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow\infty}\frac{f(x)}{g(x)} = \alpha$
---------------PROOF BY L'HOPITAL'S RULE 1--------------------

\section*{14.3: L'Hopital's Rule 3}
Suppoose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, and that $lim_{x\rightarrow\infty}f(x)=\infty=lim_{x\rightarrow\infty}g(x)$ . If $lim_{x\rightarrow\infty}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow\infty}\frac{f(x)}{g(x)} = \alpha$

\section*{15.4: Inverse functions are only functions if f(x) is a bijection}
Let $f:A\rightarrow B$ be a function. Then $f^{-1}$ is a function iff $f$ is a bijection. \\ 
--------proof should be trivial------------
 
\section*{15.5: Monotone and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval. If $f:J\rightarrow\mathbb{R}$ is continuous and one-to-one, then $f$ is monotone on J. \\ 
-----------------proof needed------------------

\section*{15.6: Inverses and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval and let $f:J\rightarrow\mathbb{R}$ be continuous and one-to-one, then $f(J)$ is an interval and $f^{-1}:f(J)\rightarrow J$ is continuous. \\ 
-----------------proof needed------------------

\section*{15.7: Inverse Derivative and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval and let $f:J\rightarrow\mathbb{R}$ be a continuous and one-to-one function. Let $b_o\in f(J)$ and suppose that $f$ is differentiable at $f^{-1}(b_o)\in J$, with $f(f^{-1}(b_o))\neq0$. Then $f^{-1}$ is differentiable at $b_o$ and $$(f^{-1})'(b_o)=\frac{1}{f'(f^{-1}(b_o))}$$\\ 
-----------------proof needed------------------


\chapter*{Section 0: Induction}

\section*{0.3 The well ordering principle for N}
If $\phi\neq$ S $\subseteq \mathbb{N}$, then S admits a minimum element (has a minimum element)
i.e. there exists some $m_o \in$ S so that $m_o \leq$ t for all t $\in$ S. \\ 
Basically, for every subset of $\mathbb{N}$, there is always a minimum element. 

\section*{0.4 The First Principle Of Mathematical Induction}
Let S $\subseteq$ $\mathbb{N}$. Iff:\\
(a) 1 $\in$ S\\
(b) For each $k \in \mathbb{N}$, if $k \in S$, then $(k+1) \in S$ \\
Then S is true for all $\mathbb{N}$

\section*{0.7 The Second Principle Of Mathematical Induction}
Let S $\subseteq$ $\mathbb{N}$. Iff:\\
(a) 1 $\in$ S\\
(b) For each $k \in \mathbb{N}$, if $\{1, 2, 3, ..., k\} \in S$, then $(k+1) \in S$ \\
Then S is true for all $\mathbb{N}$


\chapter*{Section 1: Real Numbers}

\section*{1.7: The Least Upper Bound Property}
Let $\phi\neq S \subseteq \mathbb{R}$. If S is bounded above, then $sup S \in \mathbb{R}$. 

\section*{1.9: The Greatest Lower Bound Property}
Let $\phi\neq S \subseteq \mathbb{R}$. If S is bounded below, then $inf S \in \mathbb{R}$. 

\section*{1.10: Archimedean property - I}
The archimedean property: The set $\mathbb{N} \subseteq \mathbb{R}$ is not bounded above. \\ 
Proof: Suppose $\mathbb{N}$ is bounded. Let $\beta = sup\mathbb{N}$. It follows that $\beta > n$  $\forall n\in\mathbb{N}$. Also, $\beta - 1$ is not a supremum. Therefore, there exists $k \ni \beta-1 < k$. $\beta - 1 < k = \beta < k+1$, contradicting the fact that $\beta = sup\mathbb{N}$. 

\section*{1.11: Archimedean property - II}
Let $\epsilon > 0$ be a real number. Then there exists $n_o \in \mathbb{N}$ such that $0 < \frac{1}{n_o} < \epsilon$.\\ 
Proof: If $\epsilon > 0$, then it follows that $\frac{1}{\epsilon} > 0$. Because $\mathbb{N}$ is unbounded, then we can find $n_o \in \mathbb{N}$ such that $n_o > \frac{1}{\epsilon}$. Taking inverses, $\epsilon > \frac{1}{n_o} > 0$.

\section*{1.14: Definition: Absolute Values}
(a) $|x| \geq 0$ and $|x| = 0$ if and only if x = 0\\
(b) $|xy| = |x||y|$\\
(c) $|x|-|y|\leq|x+y|\leq|x| + |y|$\\
Proof: Note: $|x|^2 = x^2$, and $|x| \geq x$\\
$|x+y|^2 \leq (|x| + |y|)^2$\\
Taking the right side, \\ 
$|x|^2 + 2|x||y| + |y|^2$\\ 
$x^2 + 2xy + y^2$\\
$(x+y)^2$\\ 
$|x+y|^2$, as required. \\ 

Note that (c) implies: \\ 
$|x - y| \leq |x - z| + |z - y|$\\ 

\section*{1.15: Absolute value and intervals}
(a) $|x - a| < \delta$ if and only if $x \in (a-\delta, a+\delta)$\\
(b) $|x - a| \leq \delta$ if and only if $x \in [a-\delta, a+\delta]$\\
(c) $0 < |x - a| < \delta$ if and only if $x \in (a-\delta, a+\delta) \backslash {a}$\\



\chapter*{Section 2: Relations, Functions, and the Uncountability of R}

\section*{2.1: Definition of Cartesian Product}
Let A and B be sets. The Cartesian product of A and B is $A x B = {(a,b): a \in A, b \in B}$. That is, AxB is the set of all possible pairs of all elements of A and B. 

\section*{2.3: Definition of Relation}
A relation between two sets A and B is a subset $\mathbb{R}$ of A x B. That is, $\mathbb{R} \subseteq A x B$. We also want aRb to mean that $(a,b) \in \mathbb{R}$.

\section*{2.10: Definition of finite, denumerable, countable, and uncountable}
A set A is said to be
(a) finite if either A = $\phi$, or there exists $n \in \mathbb{N}$ and a bijection $f: \mathbb{N} \rightarrow A$ \\
(b) denumerable if there exists a bijection $g: \mathbb{N} \rightarrow A$.\\ 
(c) countable if A is either finite or denumerable \\ 
(d) uncountable if A is not countable. \\ 
We refer to $|A|$ as the cardinality of A. 

\section*{2.15: The set of real numbers is uncountable}
We will prove instead that (0,1) is uncountable, then because (0,1), a subset of $\mathbb{R}$ is uncountable, then $\mathbb{R}$ is uncountable. If (0,1) was countable, then we could find a bijection $f: \mathbb{N} \rightarrow (0,1)$, and display it as such:\\ 
$x_1 = 0.x_{11}x_{12}x_{13} ...$\\ 
$x_1 = 0.x_{21}x_{22}x_{23} ...$, where $x_{ij}$ is an integer between 0 and 9. Then the number $0.x_{11}x_{22}x_{33}...$ is in (0, 1), but not part of $x_n$.



\chapter*{Section 3: Sequences and Limits}

\section*{3.5: Definition: Adding Limits}
If $lim_{n\rightarrow\infty}x_n = \alpha$, and $lim_{n\rightarrow\infty}y_n = \beta$, then $lim_{n\rightarrow\infty}(kx_n + y_n)$ exists and $lim_{n\rightarrow\infty}(kx_n + y_n) = k\alpha + \beta$.\\ 
Proof: Let $\epsilon > 0$, and set $\epsilon_o = \frac{\epsilon}{|k|+1}$.\\ 
Since $lim_{n\rightarrow\infty}x_n = \alpha$, there exists $N_1 \in \mathbb{N}$ so that $n\geq N_1$ implies $|x_n - \alpha| < \epsilon_o$. \\ 
Since $lim_{n\rightarrow\infty}y_n = \beta$, there exists $N_2 \in \mathbb{N}$ so that $n\geq N_2$ implies $|y_n - \beta| < \epsilon_o$. \\ 
With N:= max($N_1, N_2$), we see that $n \geq N$ implies that both $|x_n - \alpha| < \epsilon_o$, and $|y_n - \beta| < \epsilon_o$. Thus $n \geq N$ implies that \\ 
$|(kx_n+y_n) - (k\alpha+\beta)| \leq |k||x_n - \alpha|+|y_n - \beta|$\\
$|(kx_n+y_n) - (k\alpha+\beta)| \leq |k|\epsilon_o +\epsilon_o$\\
$|(kx_n+y_n) - (k\alpha+\beta)| \leq \epsilon_o(|k|+1)$\\ 
We wanted $|(kx_n+y_n)-(k\alpha+\beta)| < \epsilon$. If we know that $(|k|+1)\epsilon_o \leq \epsilon$, we would be done. Setting $e_o = \frac{\epsilon}{|k|+1}$ works. 

\section*{3.7: Every convergent sequence is bounded}
If $(x_n)_{n=1}^\infty \in \mathbb{R}^\mathbb{N}$ is a convergent sequence, then $(x_n)_{n=1}^\infty$ is bounded.\\ 
Proof: Suppose that $lim_{n\rightarrow\infty}x_n = \beta \in \mathbb{R}$. Let $\epsilon = 1$, and choose $N \in \mathbb{N}$ so that $n \geq N$ implies that $|x_n - \beta| < \epsilon = 1$. Then $n \geq N$ implies that $|x_n| \leq |x_n - \beta| + |\beta| < 1 + |\beta|$. Let M:= max$\{|x_1|, |x_2|, ... ,|x_{N-1}|, 1 + |\beta|\}$. For any $n\geq 1$, $|x_n| \leq M$, and so $(x_n)_{n=1}^\infty$ is bounded. 

\section*{3.10: Multiplying and Dividing Limits}
If $lim_{n\rightarrow\infty}x_n = \alpha$, and $lim_{n\rightarrow\infty}y_n = \beta$, then $lim_{n\rightarrow\infty}(x_ny_n) = \alpha\beta$.\\
Proof: Let $\epsilon > 0$. and set $\epsilon_o = \frac{\epsilon}{M_2 +|\alpha| + 1}$. Because $x_n$ and $y_n$ are convergent, they must be bounded. Say $|x_n| \leq M_1$ for all $n \geq 1$, and $|y_n| \leq M_2$ for all $n \geq 1$. We want to prove that there exists $N \in \mathbb{N}$ so that $n \geq N$ implies $|x_ny_n - \alpha\beta| < \epsilon$.\\ 
We know: there exists $N_1 \in \mathbb{N}$ such that $n \geq N_1$ implies $|x_n - \alpha| < \epsilon_o$ and there exists $N_2 \in \mathbb{N}$ such that $n \geq N_2$ implies $|y_n - \beta| < \epsilon_o$. So if N:= max($N_1,N_2$) and $n \geq N$, then $|x_n - \alpha| < \epsilon_o$ and $|y_n - \beta| < \epsilon_o$. That is, $n \geq N$ implies that \\ 
$|x_ny_n - \alpha\beta| \leq |x_ny_n - \alpha y_n| + |\alpha y_n - \alpha\beta|$ \\ 
$|x_ny_n - \alpha\beta| \leq |x_n - \alpha||y_n| + |\alpha||y_n - \beta|$ \\ 
$|x_ny_n - \alpha\beta| \leq |x_n - \alpha|M_2 + |\alpha||y_n - \beta|$\\ 
$|x_ny_n - \alpha\beta| \leq M_2\epsilon_o + |\alpha|\epsilon_o$ \\ 
$|x_ny_n - \alpha\beta| \leq \epsilon_o(M_2 + |\alpha|)$ \\ 
Taking $\epsilon_o = \frac{\epsilon}{M_2 +|\alpha| + 1}$, we see that $n \geq N$ implies $|x_ny_n| < (M_2+|a|)\epsilon_o < \epsilon$. \\ 

If $lim_{n\rightarrow\infty}x_n = \alpha$, and $lim_{n\rightarrow\infty}y_n = \beta$, then $lim_{n\rightarrow\infty}(x_n/y_n) = \alpha/\beta$.\\ 
Proof: 


\section*{3.14: Subsequences of a Convergent Sequence}
Let $(x_n)_{n=1}^\infty \in \mathbb{R}^\mathbb{N}$, and suppose $lim_{n\rightarrow\infty}x_n = \beta$. If $(x_{n_k})_{k=1}^\infty$ is any subsequence of $(x_n)_{n=1}^\infty$, then $lim_{n\rightarrow\infty}x_{n_k} = \beta$.\\ 
Proof: Let $\epsilon > 0$ and choose $N \in \mathbb{N}$ so that $n \geq N$ implies $|x_n-\beta|<\epsilon$. If $k\geq N$, then $n_k\geq k\geq N$, and so $|x_{n_k}-\beta| < \epsilon$. 

\section*{3.16: Squeeze Theorem}
Proof: Let $\epsilon > 0$. Choose $N_1 \in\mathbb{N}$ so that $n\geq N$ implies $|x_n-\beta| < \epsilon$. Choose Choose $N_2 \in\mathbb{N}$ so that $n\geq N$ implies $|z_n-\beta| < \epsilon$. Let $N=max(N_o,N_1,N_2)$. Then $n\geq N$ implies that $\beta - \epsilon < x_n \leq y_n \leq z_n < \beta + \epsilon$, so that $\beta - \epsilon < y_n < \beta + \epsilon$, ie. $|y_n - \beta| < \epsilon$. 

\section*{3.21 The comparison theorem}
Suppose $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ $\in \mathbb{R}^\mathbb{N}$ $\ni$ $lim x_n = \alpha$ and $lim y_n = \beta$. Suppose also that $\exists N_o \in \mathbb{N} \ni n \geq N_o$ implies $x_n \leq y_n$. Then $\alpha \leq \beta$. \\ 



\chapter*{Section 4: Bounded Sequences}

\section*{4.3: Monotone Convergence Theorem}
(a) if $x_n$ is increasing and bounded above, then $x_n$ converges to $sup{x_n}$.\\ 
(b) if $x_n$ is decreasing and bounded below, then $x_n$ converges to $inf{x_n}$.\\ 
Proof for (a): Suppose $(x_n)_{n=1}^\infty$ is bounded above, $\beta:= sup\{x_n\}_{n=1}^\infty$ exists. Let $\epsilon > 0$. Since $\beta - \epsilon < \beta = sup\{x_n\}$, there exists $N \in \mathbb{N}$ such that $\beta - \epsilon < x_N$. Since $(x_n)_{n=1}^\infty$ is increasing, $n \geq N$ implies that $\beta - \epsilon < x_N \leq x_n \leq sup{x_n}$. That is, $x \geq N$ implies that $|x_n - \beta| < \epsilon$. 

\section*{4.7: The Nested Intervals Theorem}
Suppose that $S_n$ is a nested sequence of distinct bounded intervals. Then $\cap_{n=1}^\infty S_n \neq \phi$. Writing $S_n = [a_n, b_n]$ for each $n \geq 1$, if $lim_{n\rightarrow\infty}(b_n - a_n) = 0$, then $\cap_{n=1}^\infty S_n$ consists of a single point.

\section*{4.8: Bolzano-Weierstrass Theorem}
Suppose that $(x_n)_{n=1}^\infty$ is a bounded sequence. Then there exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ which converges.



\chapter*{Section 5: Cauchy Sequences}

\section*{5.2: Definition of Cauchy Sequence}
Let $(x_n)_{n=1}^\infty\in\mathbb{R}^\mathbb{N}$. We say that $(x_n)_{n=1}^\infty$ is a Cauchy sequence if for all $\epsilon > 0$ there exists $N\in\mathbb{N}$ such that $m > n \geq N$ implies $|x_n - x_m| < \epsilon$. 

\section*{5.5: Cauchy Sequences}
Let $x_n$. The following are equivalent: \\ 
(a) $x_n$ is convergent, that is, there exists $\beta$ such that $lim x_n = \beta$.\\ 
(b) $x_n$ is a cauchy sequence. \\ 
Proof: $(a) \rightarrow (b)$. Suppose that $\beta \in \mathbb{R}$ and $lim_{n\rightarrow\infty} = \beta$. Let $\epsilon > 0$ and choose $N \in \mathbb{N}$ such that $n \geq N$ implies that $|x_n - \beta| < \frac{\epsilon}{2}$. If $m > n \geq N$, then \\ 
$|x_m - x_n| = |x_m - \beta + \beta - x_n|$
$\leq |x_m - \beta| + |x_n - \beta| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$. \\ 
By definition, $(x_n)_{n=1}^\infty$ is a Cauchy sequence. \\ 

$(b)\rightarrow(a)$. Suppose that $(x_n)_{n=1}^\infty$ is a Cauchy sequence. Step one: Prove $(x_n)_{n=1}^\infty$ is bounded. Step two: by the Bolzano-Weierstrass Theorem, there exists a subsequence $(x_{n_k})_{k=1}^\infty$ that has a limit $\beta$. Step three: Prove that the subsequence converges to $\beta$, and because a subsequence of a bounded sequence converges, then the sequence converges. 

\section*{5.9: Sequentially Compact}
A subset $E \subseteq \mathbb{R}$ is said to be sequentially compact if, given a sequence $x_n \in E^\mathbb{N}$, there exists a subsequence $x_{n_k}$ of $x_n$ which converges to some element $\beta \in \mathbb{R}$, and furthermore we must have $\beta \in E$\\ 
Every sequence in E has a subsequence that converges to an element in E. 



\chapter*{Section 6: Limit Superior and Limit Inferior}

\section*{6.2: Definition of Limit Superior and Limit Inferior}
Suppose that $(x_n)_{n=1}^\infty \in \mathbb{R}$ is a bounded sequence. We define the limit superior of $(x_n)_{n=1}^\infty$ to be $lim sup_{n\geq 1} := lim_{n\rightarrow\infty} sup_{k\geq n} x_k$, and the limit inferior to be lim inf$_{n\geq 1} := $lim$_{n\rightarrow\infty}$ inf$_{k\geq n} x_k$.

\section*{6.4: Definition}
If (x$_n$)$_{n=1}^\infty$ is not bounded above, we define lim sup$_{n\geq 1}$x$_n$ = $\infty$\\
If (x$_n$)$_{n=1}^\infty$ is not bounded below, we define lim inf$_{n\geq 1}$x$_n$ = $-\infty$

\section*{6.6: Limit Superior and Limit Inferior of Subsequences}
Let $(x_n)_{n=1}^\infty\in\mathbb{R}^\mathbb{N}$, and let $\beta = lim_{n\geq 1}sup x_n$, $\alpha = lim_{n\geq 1}inf x_n$, so that $\alpha, \beta \in \mathbb{R}\cup \{-\infty, \infty\}$. \\ 
(a) There exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ such that $lim_{k\rightarrow\infty}x_{n_k} = \beta$. \\ 
(b) There exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ such that $lim_{k\rightarrow\infty}x_{n_k} = \alpha$. \\ 
(c) If $(x_{p_k})_{k=1}^\infty$ is any convergent subsequence of $(x_n)_{n=1}^\infty$ then $\alpha\leq lim_{k\rightarrow\infty}x_{p_k}\leq\beta$

\section*{6.7: Limit Superior and Limit Inferior and Limits}
Let $(x_n)_{n=1}^\infty \in \mathbb{R}^\mathbb{N}$, and suppose that $lim_{n\rightarrow\infty} = \gamma \in \mathbb{R}$ exists. Then $lim_{n\geq 1}inf x_n = \gamma = lim_{n\geq 1}sup x_n$.\\ 
Proof: By Theorem 6.6, there exists a subsequence $(x_{n_k})_{k=1}^\infty$ of $(x_n)_{n=1}^\infty$ which converges to $\beta:= lim_{n\geq 1}supx_n$ But since $(x_n)_{n=1}^\infty$ converges to $\gamma$, every subsequence of $(x_n)_{n=1}^\infty$ also converges to $\gamma$, so $\beta = \gamma$. Similarly, $\beta = \alpha = \gamma$. 



\chapter*{Section 7: Limits}

\section*{7.2: Punctured Neighbourhood}
Let $x_o\in\mathbb{R}$. We say that a set $H \subseteq\mathbb{R}$ is a punctured neighbourhood of $x_o$ if there exists $0 < \gamma \in \mathbb{R}$ such that \\ 
(i) $0 < |x - x_o| < \gamma$ implies that $x \in H$, but\\
(ii)$x_o \not\in H$. \\ 

\section*{7.3: Epsilon Delta Proofs}
Let $x_o\in\mathbb{R}$ and suppose that $E\subseteq\mathbb{R}$ contains a punctured neighbourhood of $x_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f approaches a limit $\beta\in\mathbb{R}$ as x approaches $x_o$ if for all $\epsilon>0$ there exists $\delta>0$ such that $0 < |x-x_o| < \delta$ implies $|f(x)-\beta| < \epsilon$. 

\section*{7.6: Limit Laws}
Let $E \subseteq \mathbb{R}$ and suppose that E contains a punctured neighbourhood of $y_o\in\mathbb{R}$. If $f,g : E\rightarrow\mathbb{R}$ are functions, and $lim_{x\rightarrow y_o}f(x)= \alpha$ and $lim_{x\rightarrow y_o}g(x)= \beta$ for some $\alpha, \beta  \in\mathbb{R}$, then \\ 
$lim_{x\rightarrow y_o}(f+g)(x)= \alpha + \beta$. \\ 
Proof: Let $\epsilon > 0$. Choose $\delta_1 > 0$ such that $0 < |x-y_o|<\delta_1$ implies $|f(x)-\alpha|<\frac{\epsilon}{2}$. Choose $\delta_2 > 0$ such that $0 < |x-y_o|<\delta_2$ implies $|g(x)-\beta|<\frac{\epsilon}{2}$. Set $\delta = min(\delta_1,\delta_2) > 0$. If $0 < |x-y_o|<\delta$, then $|(f+g)(x)-(\alpha+\beta)\leq |f(x)-\alpha|+|g(x)-\beta| < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$. By definition, $lim_{x\rightarrow y_o}(f+g)(x) = \alpha+\beta$. 

\section*{7.7: Limit Laws continued}
Let $E \subseteq \mathbb{R}$ and suppose that E contains a punctured neighbourhood of $y_o\in\mathbb{R}$. If $f,g : E\rightarrow\mathbb{R}$ are functions, and $lim_{x\rightarrow y_o}f(x)= \alpha$ and $lim_{x\rightarrow y_o}g(x)= \beta$\\  
(a) If $k \in \mathbb{R}$, then $lim_{x\rightarrow y_o}(kf)(x) = k\alpha$.\\ 
(b) $lim_{x\rightarrow y_o}(fg)(x) = \alpha\beta$\\ 
(c) If $\beta \neq 0$, then $lim_{x\rightarrow y_o}\frac{f}{g}(x) = \frac{\alpha}{\beta}$.

\section*{7.8: some random ass definition}
Let $E \subseteq \mathbb{R}$ and suppose that E contains a punctured neighbourhood of $y_o\in\mathbb{R}$. Let $\beta\in\mathbb{R}$. The following are equivalent: \\ 
(a) $lim_{x\rightarrow y_o} = \beta$ \\ 
(b) If $(x_n)_{n=1}^\infty \in (\mathbb{R} \backslash \{y_o\})^\mathbb{N}$ is any sequence such that $lim_{n\rightarrow\infty}x_n = y_o$, then $lim_{n\rightarrow\infty}f(x_n) = \beta$

\section*{7.11: The Squeeze Theorem}
Suppose that E contains a punctured neighbourhood of $y_o\in\mathbb{R}$ and suppose that $f, g, h: E\rightarrow\mathbb{R}$ are functions. \\ 
(a) If $f(x)\leq g(x)\leq h(x)$ for all $x\in E\backslash\{y_o\}$, and if $lim_{x\rightarrow y_o}f(x) = \alpha = lim_{x\rightarrow y_o}h(x)$, then $lim_{x\rightarrow y_o}g(x) = \alpha$. \\ 
(b) If $|g(x)|\leq \mu$ for all $x \in E\backslash\{y_o\}$, and if $lim_{x\rightarrow y_o}f(x) = 0$, then $lim_{x\rightarrow y_o}(fg)(x) =lim_{x\rightarrow y_o}f(x)g(x) = 0$.

\section*{7.12: Comparison Theorem} 
Suppose that $E \subseteq \mathbb{R}$ contains a punctured neighbourhood of $y_o\in\mathbb{R}$ and that $f, g: E\rightarrow\mathbb{R}$ are functions. Suppose furthermore that \\ 
(i) $f(x)\leq g(x)$ for all $x\in E\backslash\{y_o\}$
(ii) $lim_{x\rightarrow y_o}f(x) = \alpha$ and $lim_{x\rightarrow y_o}g(x) = \beta$ both exist. \\ 
Proof: Let $(x_n)_{n=1}^\infty \in (E\backslash\{y_o\})^\mathbb{N}$ be any sequence satisfying $lim_{n\rightarrow\infty}x_n = y_o$. Set $w_n = f(x_n)$, $z_n = g(x_n)$, $n \in \mathbb{N}$ so that $w_n\leq z_n$ for all $n\geq 1$. Note that $lim_{n\rightarrow\infty}w_n = \alpha$, and $lim_{n\rightarrow\infty}z_n = \beta$. By the Comparison Theorem for sequences, $\alpha\leq\beta$. 



\chapter*{Section 8: Limits II}

\section*{8.2: Definition of Approaching From Either Side}
Let $y_o \in\mathbb{R}$ and suppose that $E \subseteq\mathbb{R}$ contains an interval $(y_o,y_o +\gamma)$ for some $\gamma>0$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f converges to a limit $\beta$ as x approaches $y_o$ from the right if: \\ 
For all $\epsilon>0$ there exists $\delta>0$ such that $y_o<x<y_o+\delta$ implies that $|f(x)-\beta| < \epsilon$. We write $lim_{x\rightarrow y_o^+}f(x) = \beta$. A similar definition holds for convergence of f to $\beta$ as x approaches $y_o$ from the left. 

\section*{8.3: Limits at a point}
Let $y_o \in\mathbb{R}$ and suppose that $E \subseteq\mathbb{R}$ contains a punctured neighbourhood of $y_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. The following statements are equivalent: \\ 
(a) $lim_{x\rightarrow y_o}f(x) = \beta \in \mathbb{R}$\\ 
(b) $lim_{x\rightarrow y_o^+}f(x) = \beta = lim_{x\rightarrow y_o^-}f(x)$\\ 
Proof: (a) implies (b) Suppose $lim_{x\rightarrow y_o}f(x) = \beta$. Let $\epsilon > 0$ and choose $\delta > 0$ such that $0 < |x-y_o| < \delta$ implies that $|f(x)-\beta|<\epsilon$. Then $y_o<x<y_o+\delta$ implies $|f(x)-\beta|<\epsilon$. By definition, $lim_{x\rightarrow y_o^+}f(x)=\beta$. Also, $y_o-\delta<x<y_o$ implies $|f(x)-\beta|<\epsilon$. By definition, $lim_{x\rightarrow y_o^-}f(x) = \beta$. \\ 
(b) implies (a) Suppose that (b) holds, and let $\epsilon > 0$. Then there exists $\delta_1>0$ such that $y_o<x<y+\delta_1$ implies that $|f(x)-\beta|<\epsilon$. Also, there exists $\delta_2 > 0$ such that $y_o-\delta_2 < x< y_o$ impies that $|f(x)-\beta|<\epsilon$. Hence, with $\delta = min(\delta_1, \delta_2)>0$, we have that $0 < |x-y_o|<\delta$ implies that either $y_o-\delta<x<y_o$, and so $|f(x)-\beta|<\epsilon$, or $y_o<x<y_o+\delta$, and so $|f(x)-\beta|<\epsilon$. 

\section*{8.4: More definitions}
Let $\gamma\in\mathbb{R}$ and suppose that $E\subseteq\mathbb{R}$ contains the interval $[\gamma,\infty)$. Let $f:E\rightarrow\mathbb{R}$ be a function and $\beta\in\mathbb{R}$. \\ 
(a) We say that f converges to $\beta$ as x tends to infinity if, for all $\epsilon >0$ there exists $\rho\in\mathbb{R}$ such that $x>\rho$ implies $|f(x)-\beta|<\epsilon$. We write $lim_{x\rightarrow\infty}f(x)=\beta$ when this is the case. \\ 
(b) We say that f diverges to $\infty$ as x tends to infinity if for all $\mu > 0$ there exists $\rho\in\mathbb{R}$ such that $x>\rho$ implies that $f(x)>\mu$. We write $lim_{x\rightarrow\infty}f(x) = \infty$ when this is the case.\\ 
(c) We say that f diverges to infinity as x approaches $y_o\in\mathbb{R}$ from the right if for all $\mu\in\mathbb{R}$ there exists $\delta>0$ such that $y_o<x<y_o+\delta$ implies $f(x)>\mu$. 


\chapter*{Section 9: Continuity}

\section*{9.2: Definition of Continuity}
Let $y_o\in\mathbb{R}$, and suppose that $E\subseteq\mathbb{R}$ contains a neighbourhood of $y_o$. Let $f: E\rightarrow\mathbb{R}$ be a function. We say that f is continuous at $y_o$ if $lim_{x\rightarrow y_o}f(x) = f(y_o)$; that is, for all $\epsilon>0$ there exists $\delta>0$ such that $|x-y_o|<\delta$ implies $|f(x)-f(y_o)|<\epsilon$. We say that $f$ is continuous on E if $f$ is continuous at $y_o$ for every $y_o\in E$. 

\section*{9.3: Continuity from Either Side}
Let $y_o\in\mathbb{R}$ and suppose that $[y_o,y_o+8)\subseteq E_1$ for some $\delta_1>0$. Let $f: E_1\rightarrow\mathbb{R}$ be a function. We say that $f$ is continuous from the right at $y_o$ if $f(y_o) = lim_{x\rightarrow y_o^+}f(x)$. Continuity from the left is defined similarly. Given a closed interval $[a,b]\subseteq\mathbb{R}$, and a function $f:[a,b]\rightarrow\mathbb{R}$, we say that f is continuous on $[a,b]$ if \\ 
(i) f is continuous from the right at a\\ 
(ii) f is continuous on (a,b) \\ 
(iii) f is continuous from the left at b\\

\section*{9.4}
Let $y_o\in\mathbb{R}$ and suppose that $E\subseteq\mathbb{R}$ contains a neighbourhood of $y_o$. The following are equivalent: \\ 
(a) $f$ is continuous at $y_o$. \\ 
(b) if $(x_n)_{n=1}^\infty\in E^\mathbb{N}$ and $lim_{n\rightarrow\infty}x_n=y_o$, then $lim_{n\rightarrow\infty}f(x_n)=f(y_o)$ \\ 
Proof: (a) implies (b). Suppose $f(y_o) = lim_{x\rightarrow y_o}f(x)$. Let $\epsilon>0$. Then there exists $\delta>0$ such that $|x-y_o|<\delta$ implies $|f(x)-f(y)|<\epsilon$. Now let $(x_n)_{n=1}^\infty\in E^\mathbb{N}$ be an arbitrary sequence which satisfies $lim_{n\rightarrow\infty}x_n=y_o$. Then there exists $N\in\mathbb{N}$ such that $n\geq N$ implies $|x_n-y_o|<\delta$. But then $n\geq N$ implies $|f(x_n)-f(y_o)|<\epsilon$, showing that $lim_{n\rightarrow\infty}f(x_n) = f(y_o)$. \\ 
(b) implies (a). Suppose (b) is done, and let $\beta=f(y_o)$. Since (b) is true, if we take any sequence $(x_n)_{n=1}^\infty$ in $(E\backslash\{y_o\})^\mathbb{N}$ such that $lim_{n\rightarrow\infty}x_n = y_o$, then $lim_{n\rightarrow\infty}f(x_n)  = \beta$. By Thereom 7.8, we find that $lim_{x\rightarrow y_o}=\beta = f(y_o)$. 

\section*{9.8: Composite Functions}
Let A, B, and C be sets and $f: A\rightarrow B$ and $g:B\rightarrow C$ be functions. We define the composition of g and f to be the function $gof: A\rightarrow C$, $a\mapsto g(f(a))$.

\section*{9.10: Continuity of Composite Functions}
If $f$ is continuous at $y_o$ and $g$ is continuous at $f(y_o)$, then $gof$ is continuous at $y_o$. \\ 
Proof: Let $\epsilon>0$. Since $g$ is continuous at $f(y_o)$, there exists $\delta_1>0$ such that $|w-f(y_o)|<\delta_1$ implies $|g(w)-g(f(y_o))|<\epsilon$. But f is continuous at $y_o$, so there exists $\delta>0$ such that $|x-y_o|<\delta$ implies $|f(x)-f(y_o)|<\delta_1$. Putting these together, if $|x-y_o|<\delta$, then $|f(x)-f(y_o)|<\delta_1$, and therefore $|g(f(x))-g(f(y_o))|<\epsilon$, as required. 

\section*{9.12: Bounded in E}
Let $\phi\neq E\subseteq\mathbb{R}$ and suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ is bounded on E if there exists $\mu>0$ such that $|f(x)|\leq\mu$ for all $x\in E$. In other words, $f$ is bounded on E if $sup\{|f(x)|:x\in E\}<\infty$. 

\section*{9.13: Extreme Value Theorem}
Let $a<b\in\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a continuous function. Then there exists $x_o\in[a,b]$ such that $f(x)\leq f(x_o)$ for all $x\in[a,b]$. That is, $M:=sup\{f(x):x\in[a,b]\}=max\{f(x):x\in[a,b]\}$, or the supremeum of $f(x)$ is attained at some point $x_o$. \\ 
---------NEEDS PROOF----------------

\section*{9.16: Random Lemma}
Suppose that $f:[a,b)\rightarrow\mathbb{R}$ is continuous from the right at $a$ and that $f(a)>0$. Then there exists $\gamma>0$ such that $f(x)>0$ for all $x\in[a,a+\gamma]$. 

\section*{9.17: Intermediate Value Theorem}
Let $a<b$ in $\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a continuous functions. Let $\beta\in\mathbb{R}$. \\ 
(a) If $f(a)<\beta<f(b)$, then there exists $x_o\in(a,b)$ such that $f(x_o)=\beta$. \\ 
(b) If $f(a)>\beta>f(b)$, then there exists $x_o\in(a,b)$ such that $f(x_o)=\beta$. 

\section*{9.18: Types of Discontinuities}
\paragraph*{Removable Discontinuities}
Let $y_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $y_o$. We say that a function $f:E\rightarrow\mathbb{R}$ has a removable discontinuity at $y_o$ if \\ 
(i) $lim_{x\rightarrow y_o^-}f(x) = lim_{x\rightarrow y_o^+}f(x)$ both exist, but \\ 
(ii) $f(y_o)$ either doesn't exist, or $f(y_o)\neq lim_{x\rightarrow y_o}f(x)$. \\ 
We can "remove" the discontinuity of $f$ at $y_o$ by simply "redefining" the vaue of f at $y_o$. That is, if we set $g(x)$ to be $f(x)$ for all $x\in E\backslash\{y_o\}$, and $g(x)$ equal to $lim_{x\rightarrow y_o}f(x)$ at $x=y_o$. \\ 

\paragraph*{Jump Discontinuities} 
Let $y_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $y_o$. We say that $f$ has a jump discontinuity at $y_o$ if $lim_{x\rightarrow y_o^-}f(x)$ and $lim_{x\rightarrow y_o^+}f(x)$ both exist, but $lim_{x\rightarrow y_o^-}f(x) \neq lim_{x\rightarrow y_o^+}f(x)$ Here there is no way of removing the discontinuity of $f$ at $y_o$ by choosing a "good" value for $f(y_o)$.

\paragraph*{Essential Discontinuities}
Let $y_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $y_o$. We say that $f$ has an essential singularity at $y_o$ if at least one of $lim_{x\rightarrow y_o^-}f(x)$ and $lim_{x\rightarrow y_o^+}f(x)$ does not exist (or is infinite). 



\chapter*{Section 10: Uniform Continuity}
\section*{10.2: Definition of Uniform Continuity}
Let $E\subseteq\mathbb{R}$, and suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ is uniformly continuous on E if for all $\epsilon>0$ there exists $\delta>0$ such that $x,y\in E$ and $|x-y|<\delta$ implies $|f(x)-f(y)|<\epsilon$. The key new ingredient here is that $\delta>0$ is chosen before we pick the point at which we consider continuity. In other words, the same $\delta>0$ works for all $y\in E$. 

\section*{10.4: Cauchy Sequence Lemma}
If $(x_n)_{n=1}^\infty\in E^\mathbb{N}$ is a Cauchy sequence, then $(f(x_n))_{n=1}^\infty \in\mathbb{R}^\mathbb{N}$ is a Cauchy sequence. 

\section*{10.5: Uniform Continuity and Continuity}
Let $a<b \in\mathbb{R}$, and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a function. The following are equivalent:\\ 
(a) $f$ is continuous on $[a,b]$ \\ 
(b) $f$ is uniformly continuous of $[a,b]$\\ 



\chapter*{Section 11: Differentiability}

\section*{11.2: Definition of Differentiability}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Let $f:E\rightarrow\mathbb{R}$ be a function. We say that $f$ is differentiable at $x_o$ if $f'(x_o)=lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)}{h}=lim_{x\rightarrow x_o}\frac{f(x)-f(x_o)}{x-x_o}$ exists as a real number. We refer to $f'(x_o)$ as the derivative of $f$ at $x_o$. We say that $f$ is differentiable on E provided that: \\ 
(a) E is a neighbourhood of each of its points, ie E is open, and \\ 
(b) $f$ is differentiable at every point of E 

\section*{11.4: Differentiability implications}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Let $f:E\rightarrow\mathbb{R}$ be a function. The following are equivalent: \\ 
(a) $f$ is differentiable at $x_o$; ie $f'(x_o):=lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)}{h}$ exists \\ 
(b) There exists a function $F:E\rightarrow\mathbb{R}$ such that: \\
\hspace*{5mm} (i) $f(x)=F(x)(x-x_o)+f(x_o)$ and \\
\hspace*{5mm} (ii) F is continuous at $x_o$ with $F(x)=f'(x_o)$ \\ 
(c) There exists a function $T:\mathbb{R}\rightarrow\mathbb{R}$ such that $Tx=m_ox$ for some fixed constant $m_o\in\mathbb{R}$, and all $x\in\mathbb{R}$, such that $lim_{h\rightarrow0}\frac{f(x_o+h)-f(x_o)-Th}{h} = 0$\\ 

----------------PROOF FROM ASSIGNMENT 9------------

\section*{11.5: Differentiability and Continuity}
If $x_o\in\mathbb{R}$, $E\subseteq\mathbb{R}$ is a neighbourhood of $x_o$ and $f:E\rightarrow\mathbb{R}$ is differentiable at $x_o$, then $f$ is continuous at $x_o$. \\ 
Proof: Consider $lim_{x\rightarrow x_o}f(x)-f(x_o) = lim_{x\rightarrow x_o}(\frac{f(x)-f(x_o)}{x-x_o})(x-x_o)$\\ 
$= lim_{x\rightarrow x_o}(\frac{f(x)-f(x_o)}{x-x_o})*lim_{x\rightarrow x_o}(x-x_o)$ \\ 
$= f'(x_o)* 0$\\ 
$= 0$\\ 
So $f(x_o)=lim_{x\rightarrow\infty}f(x)$, ie $f$ is continuous at $x_o$. 

\section*{11.6 Adding and Multiplying Derivatives}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Suppose that $f,g:E\rightarrow\mathbb{R}$ are functions and $k\in\mathbb{R}$ is a constant. If f and g are differentiable at $x_o$, then so is:\\ 
(a) $kf+g$, and $(kf+g)'(x_o)=k(f'(x_o))+(g'(x_o))$\\ 
(b) $fg$, and $(fg)'(x_o) = f'(x_o)g(x_o)+f(x_o)g'(x_o)$\\ 

\section*{11.11: Local Max and Local Min}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Suppose that $f:E\rightarrow\mathbb{R}$ is a function. We say that $f$ has a local maximum at $x_o$ if there exists $\delta>0$ such that $f(x_o)\geq f(x)$ for all $x\in(x_o-\delta, x_o+\delta)$. We say that $f$ has a local minimum at $x_o$ if there exists $\delta>0$ such that $f(x_o)\leq f(x)$ for all $x\in(x_o-\delta,x_o+\delta)$. 

\section*{11.13: Derivatives at Local Max and Mins}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Suppose that $f:E\rightarrow\mathbb{R}$ is a function. \\ 
(a) if f has a local maximum at $x_o$, then $\frac{f(x_o+h)-f(x_o)}{h}\geq0$ and $\frac{f(x_o+k)-f(x_o)}{k}\leq0$ for all $h<0$ and $k>0$ suffifiently small; that is, there exists $\delta>0$ such that $-\delta<h<0$ implies $\frac{f(x_o+h)-f(x_o)}{h}\geq0$, while $0<k<\delta$ implies $\frac{f(x_o+k)-f(x_o)}{k}\leq0$. \\ 
----------NEEEDS PROOF---------------------

\section*{11.14: Quotient Rule}
$(\frac{f}{g})'(x_o)=\frac{f'(x_o)g(x_o)-f(x_o)g'(x_o)}{(g(x_o))^2}$

\section*{11.16: Chain Rule}
Let $x_o\in\mathbb{R}$ and $E\subseteq\mathbb{R}$ be a neighbourhood of $x_o$. Suppose that \\ 
(a) $f:E\rightarrow\mathbb{R}$ is a function \\ 
(b) there exists a neighbourhood of H of $f(x_o)$ such that $f(E)\subseteq$ and \\ 
(c) $g:H\rightarrow\mathbb{R}$ is a function. \\ 
If $f$ is differentiable at $x_o$ and $g$ is differentiable at $f(x_o)$, then $gof$ is differentiable at $x_o$, and $(gof)'(x_o)=g'(f(x_o))*f'(x_o)$




\chapter*{Section 12: Derivatives}

\section*{12.2: Rolle's Theorem}
Let $a<b\in\mathbb{R}$ and suppose that $f:[a,b]\rightarrow\mathbb{R}$ is a function such that: \\ 
(a) $f$ is continuous on $[a,b]$ \\ 
(b) $f$ is differentiable on $(a,b)$\\ 
(c) $f(a) =f(b)=0$\\ 
There exists a point $x_o\in(a,b)$ where $f'(x_o)=0$. 

\section*{12.4: Mean Value Theorem}
Let $a<b\in\mathbb{R}$ and $f:[a,b]\rightarrow\mathbb{R}$ be a function. Suppose that \\ 
(a) $f:[a,b]\rightarrow\mathbb{R}$ is continuous, and \\ 
(b) $f$ is differentiable on (a,b). \\ 
Then there exists $x_o\in(a,b)$ such that $f'(x_o)=\frac{f(b)-f(a)}{b-a}$

\section*{12.5: Cauchy's Mean Value Theorem}
Suppose that $f,g:[a,b]\rightarrow\mathbb{R}$ are continuous and differentiable. Then there exists $x_o\in(a,b)$ such that $g'(x_o)(f(b)-f(a))=f'(x_o)(g(b)-g(a))$. 

\section*{12.7: Increasing and Decreasing on an interval}
Let $\phi\neq E\subseteq\mathbb{R}$ and $f:E\rightarrow\mathbb{R}$ be a function. We say that: \\ 
$f$  is increasing on E if $x<y$ in E implies $f(x)\leq f(y)$\\
$f$  is strictly increasing on E if $x<y$ in E implies $f(x)< f(y)$\\
$f$  is decreasing on E if $x<y$ in E implies $f(x)\geq f(y)$\\
$f$  is strictly decreasing on E if $x<y$ in E implies $f(x)> f(y)$\\ 

\section*{12.8: Derivatives on an Increasing/Decreasing Interval}
Suppose that $f,g:[a,b]\rightarrow\mathbb{R}$ are continuous and differentiable. \\ 
(I) If $f'(x)>0$ for all $x\in(a,b)$, then $f$ is strictly increasing on $(a,b)$. \\ 
(II) If $f'(x)<0$ for all $x\in(a,b)$, then $f$ is strictly decreasing on $(a,b)$. \\ 
(III) If $f'(x)=0$ for all $x\in(a,b)$, then $f$ is constant on $(a,b)$. \\ 
Proof: (I) By the Mean Value Theorem, if $a<x_1<x_2<b$, then $f$ is differentiable and continuous on $(x_1,x_2)$. So there exists $x_o\in(x_1,x_2)$ such that $f(x_2)-f(x_1)=f'(x_o)(x_2-x_1)$. But $f'(x_o)>0$, $x_2-x_1>0$, so $f(x_2)-f(x_1)>0$, ie. $f$ is strictly increasing. \\ 
(II) Apply (I) to $g=-f$ \\ 
(III) By the Mean Value Theorem, for any $a<x_1<x_2<b$, $f$ is differentiable3 and continuous on $(x_1,x_2)$. So there exists $x_o\in(x_1,x_2)$ such that $f(x_2)-f(x_1)=f'(x_o)(x_2-x_1)$. But $f'(x)=0$ for all $x\in(a,b)$, so $f'(x_o)=0$, whence $f(x_2)-f(x_1)$. Since $x_1<x_2$ in $(a,b)$ were arbitrary, $f$ is constant on $(a,b)$. 

\section*{12.9}
If $f$ is increasing, then $f(x_o)\leq f(x_o^+)$, and $f(x_1)\geq f(x_1^-)$. \\ 
----------------Proof from assignment 9-----------------

\section*{12.11}
If f is an increasing function, then it has countably many discontinuities.  

\section*{12.13: Darboux's Theorem}
Suppose that $\phi\neq E\subseteq\mathbb{R}$ and that $[a,b]\subseteq E$ for some $a<b$ in $\mathbb{R}$. Suppose furthermore that $f:E\rightarrow\mathbb{R}$ is a function and that $f'(x)$ exists for all $x\in[a,b]$. If $f'(a)<y_o<f'(b)$, then there exists $x_o\in(a,b)$ such that $f'(x_o)=y_o$. 

\section*{12.14: Concavity}
Let $a<b\in\mathbb{R}$ and suppose that $f:(a,b)\rightarrow\mathbb{R}$ is a function. We say that $f$ is \\ 
(a) Concave up on (a,b) if $a<x_o<y_o<b$ implies that $\frac{f(x_o)+f(y_o)}{2}\geq f(\frac{x_o+y_o}{2})$. \\ 
(b) Concave down on (a,b) if $a<x_o<y_o<b$ implies that $\frac{f(x_o)+f(y_o)}{2}\leq f(\frac{x_o+y_o}{2})$. \\ 
We say that $f$ is strictly CU or CD if the inequalities are strict. 

\section*{12.16: Concavity and the Second Derivative}
Let $a<b$ in $\mathbb{R}$ and suppose that $f:(a,b)\rightarrow\mathbb{R}$ is a function that is continuous. The following are equivalent: \\ 
(a) $f''\geq0$\\ 
(b) $f$ is concave up on $(a,b)$. \\ 
--------------NEED PROOF------------------ 

\section*{12.17: Point of inflection}
A point $x_o\in(a,b)$ is said to be a point of inflection for $f$ if there exists $\delta>0$ such that either \\ 
(a) $f$ is strictly CU on $(x_o-\delta,x_o)$ and strictly CD on $(x_o,x_o+\delta)$, or \\ 
(b) $f$ is strictly CD on $(x_o-\delta,x_o)$ and strictly CU on $(x_o,x_o+\delta)$ 

\section*{12.18: Point of Inflection and the Second Derivative}
If $f$ has a point of inflection at $x_o$, then $f''(x_o)=0$. 
---------------NEED PROOF----------------- 



\chapter*{Section 13: Taylor's Theorem}
\section*{13.2: Langrange Remainder}
Let $a<b$ in $\mathbb{R}$ and $f:(a,b)\rightarrow\mathbb{R}$ be a function. Let $n\in\mathbb{N}$ be an integer and suppose that $f$ is n-times differentiable on (a,b). Given $a<x_o<b$, we define the Taylor polynomial of $f$ by degree n centered at $x_o$ to be $P_n(x)=\sum_{k=0}^n\frac{f^kx_o}{k!}(x-x_o)^k$. 

\section*{13.3: Taylor's Theorem}
Let $n\in\mathbb{N}$ and $a,b\in\mathbb{R}\cup\{-\infty,\infty\}$ with $a<b$. Suppose that $f:(a,b)\rightarrow\mathbb{R}$ is an $(n+1)$-times differentiable function on $(a,b)$, and let $x_o\in(a,b)$. Given $x\in(a,b)$, there exists a number $z_x$ between $x_o$ and $x$ such that $$f(x)=P_n^{f_1x_o}(x) + \frac{f^{n+1}(z_x)}{(n+1)!}(x-x_o)^{n+1}$$



\chapter*{Section 14: L'Hopital's Rule}
\section*{14.1: L'Hopital's Rule 1}
Suppose that $a<b$ in $\mathbb{R}$ and $x_o\in(a,b)$. Suppoose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, except possibly at $x_o$, and that $lim_{x\rightarrow x_o^+}f(x)=0=lim_{x\rightarrow x_o^+}g(x)$. If $lim_{x\rightarrow x_o^+}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow x_o^+}\frac{f(x)}{g(x)} = \alpha$

\section*{14.2: L'Hopital's Rule 2}
Suppoose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, and that $lim_{x\rightarrow\infty}f(x)=0=lim_{x\rightarrow\infty}g(x)$. If $lim_{x\rightarrow\infty}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow\infty}\frac{f(x)}{g(x)} = \alpha$
---------------PROOF BY L'HOPITAL'S RULE 1--------------------

\section*{14.3: L'Hopital's Rule 3}
Suppoose that $f,g:(a,b)\rightarrow\mathbb{R}$ are differentiable, and that $lim_{x\rightarrow\infty}f(x)=\infty=lim_{x\rightarrow\infty}g(x)$ . If $lim_{x\rightarrow\infty}\frac{f'(x)}{g'(x)} = \alpha$, then $lim_{x\rightarrow\infty}\frac{f(x)}{g(x)} = \alpha$



\chapter*{Section 15: Inverse Functions}
\section*{15.2: Definition of an Inverse Function}
For any function $f:A\rightarrow B$, the inverse of $f$, denoted by $f^{-1}$, is the set of all pairs $(b,a)$, where $(a,b)\in f$.

\section*{15.4: Inverse functions are only functions if f(x) is a bijection}
Let $f:A\rightarrow B$ be a function. Then $f^{-1}$ is a function iff $f$ is a bijection. \\ 
--------proof should be trivial------------
 
\section*{15.5: Monotone and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval. If $f:J\rightarrow\mathbb{R}$ is continuous and one-to-one, then $f$ is monotone on J. \\ 
-----------------proof needed------------------

\section*{15.6: Inverses and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval and let $f:J\rightarrow\mathbb{R}$ be continuous and one-to-one, then $f(J)$ is an interval and $f^{-1}:f(J)\rightarrow J$ is continuous. \\ 
-----------------proof needed------------------

\section*{15.7: Inverse Derivative and Bijections}
Let $J\subseteq\mathbb{R}$ be an interval and let $f:J\rightarrow\mathbb{R}$ be a continuous and one-to-one function. Let $b_o\in f(J)$ and suppose that $f$ is differentiable at $f^{-1}(b_o)\in J$, with $f(f^{-1}(b_o))\neq0$. Then $f^{-1}$ is differentiable at $b_o$ and $$(f^{-1})'(b_o)=\frac{1}{f'(f^{-1}(b_o))}$$\\ 
-----------------proof needed------------------

\end{document}