\documentclass[10pt,english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1.5in,bmargin=1.5in,lmargin=1.5in,rmargin=1.5in}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}

\makeatletter
\usepackage{enumitem}
\newlength{\lyxlabelwidth}

\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}

%\usepackage{txfonts}

\usepackage{microtype}

\usepackage{calc}
\usepackage{enumitem}
\setenumerate{leftmargin=!,labelindent=0pt,itemindent=0em,labelwidth=\widthof{\ref{last-item}}}


\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}


\makeatother

\usepackage{babel}
\begin{document}
\noindent \begin{center}
\textbf{\large{}MATH 235 - Assignment 6}\\
\textbf{\large{}Chris Ji 20725415}
\par\end{center}{\large \par}
\medskip{}

\begin{enumerate}
\item \begin{enumerate}
    \item By theorem 9.5.1, $\text{dim}\mathbb{V}=\text{dim}\mathbb{U}+\text{dim}\mathbb{W}_1$, and $\text{dim}\mathbb{V}=\text{dim}\mathbb{U}+\text{dim}\mathbb{W}_2$. Then, subtracting these two equations from each other we get $0=\text{dim}\mathbb{W}_1-\text{dim}\mathbb{W}_2\Rightarrow\text{dim}\mathbb{W}_1=\text{dim}\mathbb{W}_2$. 
    \item Let $\mathbb{V}=\mathbb{R}^3$, and $\mathbb{U}=\begin{bmatrix}1\\0\\0\end{bmatrix}$. Then $\mathbb{R}^3=\text{Span}\left\{\begin{bmatrix}1\\0\\0\end{bmatrix}\right\}+\text{Span}\left\{\begin{bmatrix}0\\1\\1\end{bmatrix}\right\}$, and $\mathbb{R}^3=\text{Span}\left\{\begin{bmatrix}1\\0\\0\end{bmatrix}\right\}+\text{Span}\left\{\begin{bmatrix}1\\1\\1\end{bmatrix}\right\}$, but $\mathbb{W}_1=\text{Span}\left\{\begin{bmatrix}0\\1\\1\end{bmatrix}\right\}\neq\text{Span}\left\{\begin{bmatrix}1\\1\\1\end{bmatrix}\right\}=\mathbb{W}_2$
\end{enumerate}

\pagebreak
\item Suppose that $\{\vec{v}_1,\ldots,\vec{v}_k\}$ is an orthogonal basis for $\mathbb{S}$, and $\{\vec{v}_{k+1},\ldots,\vec{v}_n\}$ is an orthogonal basis for $\mathbb{S}^\perp$. Hence $\{\vec{v}_1,\ldots,\vec{v}_k,\vec{v}_{k+1},\ldots,\vec{v}_n\}$ is an orthogonal basis for $\mathbb{V}$, and every $\vec{x}$ in $\mathbb{V}$ can be expressed by $\vec{x}=\frac{\langle\vec{x},\vec{v}_1\rangle}{||\vec{v}_1||^2}\vec{v}_1+\ldots+\frac{\langle\vec{x},\vec{v}_k\rangle}{||\vec{v}_k||^2}\vec{v}_k+\frac{\langle\vec{x},\vec{v}_{k+1}\rangle}{||\vec{v}_{k+1}||^2}\vec{v}_{k+1}+\ldots+\frac{\langle\vec{x},\vec{v}_n\rangle}{||\vec{v}_n||^2}\vec{v}_n$. Then $\text{proj}_{\mathbb{S}^\perp}(\vec{x})=\frac{\langle\vec{x},\vec{v}_{k+1}\rangle}{||\vec{v}_{k+1}||^2}\vec{v}_{k+1}+\ldots+\frac{\langle\vec{x},\vec{v}_n\rangle}{||\vec{v}_n||^2}\vec{v}_n$, and\\  $\text{perp}_\mathbb{S}(\vec{x})=\vec{x}-\text{proj}_\mathbb{S}\vec{x}=\vec{x}-\left(\frac{\langle\vec{x},\vec{v}_1\rangle}{||\vec{v}_1||^2}\vec{v}_1+\ldots+\frac{\langle\vec{x},\vec{v}_k\rangle}{||\vec{v}_k||^2}\vec{v}_k\right)$, and so \begin{align*}\text{proj}_{\mathbb{S}^\perp}\vec{x}&=\text{perp}_\mathbb{S}\vec{x}\\\frac{\langle\vec{x},\vec{v}_{k+1}\rangle}{||\vec{v}_{k+1}||^2}\vec{v}_{k+1}+\ldots+\frac{\langle\vec{x},\vec{v}_n\rangle}{||\vec{v}_n||^2}\vec{v}_n&=\vec{x}-\left(\frac{\langle\vec{x},\vec{v}_1\rangle}{||\vec{v}_1||^2}\vec{v}_1+\ldots+\frac{\langle\vec{x},\vec{v}_k\rangle}{||\vec{v}_k||^2}\vec{v}_k\right)\\\Rightarrow\vec{x}&=\left(\frac{\langle\vec{x},\vec{v}_1\rangle}{||\vec{v}_1||^2}\vec{v}_1+\ldots+\frac{\langle\vec{x},\vec{v}_k\rangle}{||\vec{v}_k||^2}\vec{v}_k\right)+\frac{\langle\vec{x},\vec{v}_{k+1}\rangle}{||\vec{v}_{k+1}||^2}\vec{v}_{k+1}+\ldots+\frac{\langle\vec{x},\vec{v}_n\rangle}{||\vec{v}_n||^2}\vec{v}_n\end{align*} as expected.

\pagebreak
$\text{perp}_\mathbb{S}\vec{x}=\vec{x}-\text{proj}_\mathbb{S}(\vec{x})$. This can be imagined graphically as subtracting all elements of $\mathbb{S}$ that are present in $\vec{x}$ from $\vec{x}$. This is clearly the same as $\text{proj}_{\mathbb{S}^\perp}(\vec{x})$, as it is finding all of the elements of $x$ that are in $\mathbb{S}^\perp$, or all of the elements of $\vec{x}$ that are not in $\mathbb{S}$, which is equivalent to subtracting all elements of $\mathbb{S}$ that are present in $\vec{x}$ from $\vec{x}$, which is $\text{perp}_\mathbb{S}\vec{x}$.

\pagebreak
\item $A\sim\begin{bmatrix}1&0&0&1\\0&1&0&1\\0&0&1&-1\end{bmatrix}$, thus a basis for $\text{Row}(A)$ is $\left\{\begin{bmatrix}1\\0\\0\\1\end{bmatrix},\begin{bmatrix}0\\1\\0\\1\end{bmatrix},\begin{bmatrix}0\\0\\1\\-1\end{bmatrix}\right\}$, and a basis for $\text{Null}(A)$ is $\left\{\begin{bmatrix}-1\\-1\\1\\1\end{bmatrix}\right\}$. Then $\vec{v}=\begin{bmatrix}1\\2\\3\\4\end{bmatrix}=a\begin{bmatrix}1\\0\\0\\1\end{bmatrix}+b\begin{bmatrix}0\\1\\0\\1\end{bmatrix}+c\begin{bmatrix}0\\0\\1\\-1\end{bmatrix}+d\begin{bmatrix}-1\\-1\\1\\1\end{bmatrix}$, for some real scalars $a,b,c,d$. Putting this into a matrix, $\begin{amatrix}{4}1&0&0&-1&1\\0&1&0&-1&2\\0&0&1&1&3\\1&1&-1&1&4\end{amatrix}\sim\begin{amatrix}{4}1&0&0&0&0\\0&1&0&0&1\\0&0&1&0&4\\0&0&0&1&-1\end{amatrix}$, and so $\begin{bmatrix}1\\2\\3\\4\end{bmatrix}=0\left(\begin{bmatrix}1\\0\\0\\1\end{bmatrix}\right)+1\left(\begin{bmatrix}0\\1\\0\\1\end{bmatrix}\right)+4\left(\begin{bmatrix}0\\0\\1\\1\end{bmatrix}\right)-1\left(\begin{bmatrix}-1\\-1\\1\\1\end{bmatrix}\right)=\begin{bmatrix}0\\1\\4\\5\end{bmatrix}+\begin{bmatrix}1\\1\\-1\\-1\end{bmatrix}$. So $\vec{v}=\vec{a}+\vec{b}$, where $\vec{a}=\begin{bmatrix}0\\1\\4\\5\end{bmatrix},\vec{b}=\begin{bmatrix}1\\1\\-1\\-1\end{bmatrix}$

\pagebreak
\item Setting $\vec{y}=\begin{bmatrix}5\\2\\-2\end{bmatrix}$, and $X=\begin{bmatrix}1&-1\\1&0\\1&1\end{bmatrix}$. Therefore, by Theorem 9.6.2 we have $\vec{a}=\begin{bmatrix}a\\b\end{bmatrix}=(X^TX)^{-1}X^T\vec{y}=\left(\begin{bmatrix}3&0\\0&2\end{bmatrix}\right)^{-1}\begin{bmatrix}5\\-7\end{bmatrix}=\begin{bmatrix}\frac{5}{3}\\-\frac{7}{2}\end{bmatrix}$. Thus, we find $y=\frac{5}{3}-\frac{7}{2}x$ is the best fitting equation for the data.

\pagebreak
\item Let $\vec{x},\vec{y}$ be vectors in $\mathbb{V}$, and $\{\vec{w}_1,\ldots,\vec{w}_n\}$ be an orthogonal basis for $\mathbb{W}$. Then \begin{align*}\text{proj}_\mathbb{W}(s\vec{x}+t\vec{y})&=\sum_{i=1}^n\frac{\langle s\vec{x}+t\vec{y},\vec{w}_i\rangle}{||\vec{w}_i||^2}\vec{w}_i\\&=\sum_{i=0}^n\frac{s\langle\vec{x},\vec{w}_i\rangle+t\langle\vec{y},\vec{w}_i\rangle}{||\vec{w}_i||^2}\vec{w}_i\\&=\sum_{i=0}^n\left(s\frac{\langle\vec{x},\vec{w}_i\rangle}{||\vec{w}_i||^2}\vec{w}_i+t\frac{\langle\vec{y},\vec{w}_i\rangle}{||\vec{w}_i||^2}\vec{w}_i\right)\\&=s(\text{proj}_\mathbb{W}\vec{x})+t(\text{proj}_\mathbb{W}\vec{y})\end{align*} and so $\text{proj}_\mathbb{W}$ is a linear operator on $\mathbb{V}$. For a vector $\vec{v}$ to be in the kernel of $\text{proj}_\mathbb{W}$, we have  $\text{proj}_\mathbb{W}\vec{v}=\vec{0}$. By the definition of the projection, $\text{proj}_\mathbb{W}\vec{v}=\sum_{i=1}^n\left(\frac{\langle\vec{a},\vec{v}_i\rangle}{||\vec{w}_i||^2}\vec{w}_i\right)$. Clearly $\langle\vec{v},\vec{w}_i\rangle$ must equal zero for all $i\in[1,n]$. In other words, the kernel is the set of all $\{\vec{v}\in\mathbb{V}|\langle\vec{v},\vec{w}\rangle=0\text{ for all }\vec{w}\in\mathbb{W}\}$, which is exactly our definition of $\mathbb{W}^\perp$.

\pagebreak
\item Let $A=\begin{bmatrix}1&1\\-1&-2\\3&-2\end{bmatrix}$, $\vec{b}=\begin{bmatrix}-2\\3\\2\end{bmatrix}$, and $\vec{x}=\begin{bmatrix}x_1\\x_2\end{bmatrix}$. Since we want to minimize $||A\vec{x}-\vec{b}||$, we solve the system $A^TA\vec{x}=A^T\vec{y}$. We find $A^TA=\begin{bmatrix}11&-3\\-3&9\end{bmatrix}$, and since it is invertible, $\vec{x}=(A^TA)^{-1}A^T\vec{y}=\frac{1}{90}\begin{bmatrix}9&3\\3&11\end{bmatrix}\begin{bmatrix}1\\-12\end{bmatrix}=\begin{bmatrix}\frac{-3}{10}\\\frac{-43}{30}\end{bmatrix}$, so we can see that the vector $\vec{x}=\begin{bmatrix}-\frac{3}{10}\\-\frac{43}{30}\end{bmatrix}$ minimizes $||A\vec{x}-\vec{b}||$. 


\end{enumerate}

\end{document}
